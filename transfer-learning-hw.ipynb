{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 導入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#FNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "#CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "#data preprocessing\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 導入cifar10的資料並整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀cifar10資料\n",
    "(x_train, y_train0), (x_test, y_test0) = datasets.cifar10.load_data()\n",
    "\n",
    "#標準化\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "#Onehot encoding\n",
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(x_train.shape[0])\n",
    "x_sample = x_train[idx]\n",
    "y_sample = y_train0[idx].squeeze()\n",
    "\n",
    "plt.imshow(x_sample)\n",
    "plt.title(name_list[y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立卷積神經網路 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷積層filter數量改為9,81,243，全連接層神經元改為66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers = [Conv2D(9,(3,3), input_shape=(32,32,3), padding='same',activation='relu',name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(81,(3,3),padding='same',activation='relu',name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(243,(3,3),padding='same',activation='relu',name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=66, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 32, 32, 9)         252       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 9)         0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 16, 16, 81)        6642      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 81)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 8, 8, 243)         177390    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 66)                16104     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                670       \n",
      "=================================================================\n",
      "Total params: 201,058\n",
      "Trainable params: 201,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential(CNN_layers+FC_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batchsize改為123 epochs為3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "407/407 [==============================] - 38s 94ms/step - loss: 1.9066 - categorical_accuracy: 0.2764 - val_loss: 1.7411 - val_categorical_accuracy: 0.3359\n",
      "Epoch 2/3\n",
      "407/407 [==============================] - 38s 92ms/step - loss: 1.6373 - categorical_accuracy: 0.3926 - val_loss: 1.5346 - val_categorical_accuracy: 0.4306\n",
      "Epoch 3/3\n",
      "407/407 [==============================] - 36s 88ms/step - loss: 1.5185 - categorical_accuracy: 0.4439 - val_loss: 1.4830 - val_categorical_accuracy: 0.4633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c2e0c74548>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=123, epochs=3,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 觀察準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4902 - categorical_accuracy: 0.4603\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.4830 - categorical_accuracy: 0.4633\n",
      "Train Accuracy: 46.02600038051605\n",
      "Test Accuracy: 46.32999897003174\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(x_train, y_train)\n",
    "score_test = model.evaluate(x_test, y_test)\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 導入cifar100的資料並整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀cifar100資料\n",
    "(u_train, v_train0), (u_test, v_test0) = datasets.cifar100.load_data()\n",
    "\n",
    "#標準化\n",
    "u_train = u_train / u_train.max()\n",
    "u_test = u_test / u_test.max()\n",
    "\n",
    "#Onehot encoding\n",
    "v_train = to_categorical(v_train0, 100)\n",
    "v_test = to_categorical(v_test0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用Frozen的方式訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新增cifar100的全連接層，神經元分別為123,87,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_layers_CF100 = [Dense(units=123, activation='relu'),\n",
    "                   Dense(units=87, activation='relu'),\n",
    "                   Dense(units=100, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CF100=Sequential(CNN_layers+FC_layers_CF100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 32, 32, 9)         252       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 9)         0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 16, 16, 81)        6642      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 81)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 8, 8, 243)         177390    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 243)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 123)               30012     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 87)                10788     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               8800      \n",
      "=================================================================\n",
      "Total params: 233,884\n",
      "Trainable params: 49,600\n",
      "Non-trainable params: 184,284\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CF100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CF100.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "407/407 [==============================] - 13s 31ms/step - loss: 3.9871 - categorical_accuracy: 0.0870 - val_loss: 3.7064 - val_categorical_accuracy: 0.1220\n",
      "Epoch 2/3\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 3.6255 - categorical_accuracy: 0.1370 - val_loss: 3.5840 - val_categorical_accuracy: 0.1451\n",
      "Epoch 3/3\n",
      "407/407 [==============================] - 12s 29ms/step - loss: 3.5211 - categorical_accuracy: 0.1543 - val_loss: 3.4820 - val_categorical_accuracy: 0.1623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c2e1381d08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CF100.fit(u_train,v_train,batch_size=123, epochs=3,validation_data=(u_test, v_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 8ms/step - loss: 3.4556 - categorical_accuracy: 0.1652\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 3.4820 - categorical_accuracy: 0.1623\n",
      "Train Accuracy: 16.516000032424927\n",
      "Test Accuracy: 16.23000055551529\n"
     ]
    }
   ],
   "source": [
    "score_train = model_CF100.evaluate(u_train, v_train)\n",
    "score_test = model_CF100.evaluate(u_test, v_test)\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看舊模型準確率是否受影響"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 舊模型表現不變，因為訓練方式使用frozen，沒有再將借來的網路重新訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4902 - categorical_accuracy: 0.4603\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.4830 - categorical_accuracy: 0.4633\n",
      "Train Accuracy: 46.02600038051605\n",
      "Test Accuracy: 46.32999897003174\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(x_train, y_train)\n",
    "score_test = model.evaluate(x_test, y_test)\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
